{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import pdftables_api\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code goes to the site and gets all pdfs that were posted on the site in the past 800 days(approx 2 years). \n",
    "#If we want to go further back, just change the num_days_to_go_behind variable and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 s, sys: 1.23 s, total: 18.8 s\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "default_url = 'https://doc.dc.gov/sites/default/files/dc/sites/doc/publication/attachments/'\n",
    "initial_start_date = datetime.now().date() - timedelta(days=12)\n",
    "initial_end_date = datetime.now().date() - timedelta(days=6)\n",
    "num_days_to_go_behind = 800\n",
    "\n",
    "for i in np.arange(1, num_days_to_go_behind):\n",
    "    \n",
    "    start_date =  initial_start_date - (i*timedelta(days=1))\n",
    "    end_date = initial_end_date -  (i*timedelta(days=1))\n",
    "    \n",
    "    start_month = start_date.strftime('%B')\n",
    "    end_month = end_date.strftime('%B')\n",
    "    \n",
    "    custom_url = default_url + str(start_month) + '%20'+ str(start_date.day) + '%20through%20' \\\n",
    "                  + str(end_month) + '%20' + str(end_date.day) + '%202018.pdf'\n",
    "    \n",
    "    r = requests.get(url=custom_url)\n",
    "    if r.status_code == 200:\n",
    "        filename = 'weekly_corrections_data/pdf/corrections_data' + str(start_date) + '_' + str(end_date) +  '_.pdf'\n",
    "        with open(filename, 'wb') as infile:\n",
    "            infile.write(r.content)\n",
    "'Number of files written = '+str(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Convert to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to https://pdftables.com/pdf-to-excel-api and create a token as shown on the site. \n",
    "#Go to https://github.com/pdftables/python-pdftables-api and see how the api can be used to convert pdf to excel\n",
    "pdftables = pdftables_api.Client('insert token here', timeout=(60, 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 747 ms, sys: 72.2 ms, total: 819 ms\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"weekly_corrections_data/pdf/*.pdf\"):\n",
    "    out_file = file.replace('pdf', 'excel').replace('.excel', '.xlsx')\n",
    "    pdftables.xlsx(file, out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel(file):\n",
    "    xl = pd.ExcelFile(file)\n",
    "    xl.sheet_names\n",
    "    df = pd.read_excel(xl, 'Page 1', header=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Clean and Write it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gender(x):\n",
    "    if 'Male' in x:\n",
    "        return 'Male'\n",
    "    elif 'Female' in x:\n",
    "        return 'Female'\n",
    "    else:\n",
    "        return None\n",
    "    return x\n",
    "\n",
    "def clean_file(df):\n",
    "    if 'Indicator' not in df.columns:\n",
    "        df[['Indicator', 'SEX']] = pd.DataFrame(df['Indicator SEX'].fillna('-').str.split(' ',1).tolist(),\n",
    "                                   columns = ['Indicator','SEX'])\n",
    "    else:\n",
    "        df['Indicator'] = df.Indicator.fillna('-')\n",
    "    \n",
    "    df['Location'] = df.Location.fillna('-')\n",
    "    df.columns = [col.replace('\\n', '_') for col in df.columns]\n",
    "    df = df[~df.Indicator.str.contains('Total')].reset_index(drop=True).copy()\n",
    "    df = df[~df.Location.str.contains('Total')].reset_index(drop=True).copy()\n",
    "\n",
    "    df['gender'] = df.Indicator.apply(lambda x: get_gender(x), 1)\n",
    "    df.loc[(df.SEX.isnull() & (df.gender.notnull())), 'SEX'] = df.gender\n",
    "    df.drop(['gender'], 1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Reshaping dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataframe(df):\n",
    "    \n",
    "    df_reshape = pd.melt(df, id_vars=[\"Location\", \"Indicator\", \"SEX\", \"Operating_Capacity\"], \n",
    "                      var_name=\"date_day\", value_name=\"num_people\").reset_index(drop=True).copy()\n",
    "    df_reshape['date'] = df_reshape.date_day.apply(lambda x: x.split('_')[0])\n",
    "    df_reshape['Location'] = df_reshape.Location.replace('-', np.nan).ffill()\n",
    "    df_reshape['Operating_Capacity'] = df_reshape.Operating_Capacity.fillna('-')\n",
    "    \n",
    "    return df_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Write to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(df_reshape, file):\n",
    "    outfile = file.replace('.xlsx', '').replace('excel', 'csv')\n",
    "    filename = outfile + '_' + str(df_reshape.date.min()).replace('/', '-') + '_' + str(df_reshape.date.max()).replace('/', '-') + '.csv'\n",
    "    df_reshape.to_csv(filename , sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Calling All functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 967 ms, sys: 47.4 ms, total: 1.01 s\n",
      "Wall time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for file in glob.glob(\"weekly_corrections_data/excel/*.xlsx\"):\n",
    "    df = read_excel(file)\n",
    "    df = clean_file(df)\n",
    "    df_reshape = reshape_dataframe(df)\n",
    "    write_csv(df_reshape, file)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
